{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBhk8cq71S90ifNOJJ9BCE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaih/Perci-rajai/blob/master/MOST_WORKING_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mistral_ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSDKJVVFR-NY",
        "outputId": "b380b32f-5ee3-4ac6-b0f7-09e55b888594"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistral_ocr\n",
            "  Downloading mistral_ocr-0.6.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mistralai>=1.5.1 (from mistral_ocr)\n",
            "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from mistral_ocr) (1.2.1)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai>=1.5.1->mistral_ocr)\n",
            "  Downloading eval_type_backport-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from mistralai>=1.5.1->mistral_ocr) (0.28.1)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai>=1.5.1->mistral_ocr)\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from mistralai>=1.5.1->mistral_ocr) (2.11.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from mistralai>=1.5.1->mistral_ocr) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from mistralai>=1.5.1->mistral_ocr) (6.0.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mistralai>=1.5.1->mistral_ocr) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai>=1.5.1->mistral_ocr) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai>=1.5.1->mistral_ocr) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai>=1.5.1->mistral_ocr) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai>=1.5.1->mistral_ocr) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai>=1.5.1->mistral_ocr) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai>=1.5.1->mistral_ocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai>=1.5.1->mistral_ocr) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai>=1.5.1->mistral_ocr) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->mistralai>=1.5.1->mistral_ocr) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->mistralai>=1.5.1->mistral_ocr) (1.3.1)\n",
            "Downloading mistral_ocr-0.6.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.3.0-py3-none-any.whl (6.1 kB)\n",
            "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: invoke, eval-type-backport, mistralai, mistral_ocr\n",
            "Successfully installed eval-type-backport-0.3.0 invoke-2.2.1 mistral_ocr-0.6.0 mistralai-1.9.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install mcp_util"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8MOD2jnS2tO",
        "outputId": "9be634c9-9bfd-4156-cb3c-07ed1e488fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement mcp_util (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for mcp_util\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0DOiD7HJGXS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c45cd47-7c63-4902-ffca-8de150568b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DICTONARY\n",
            "{'id': 'b3fb04ca269c4bbfbcfab7323cdb841c', 'object': 'chat.completion', 'model': 'mistral-small-latest', 'usage': UsageInfo(prompt_tokens=370, completion_tokens=134, total_tokens=504, prompt_audio_seconds=Unset()), 'created': 1763605999, 'choices': [ChatCompletionChoice(index=0, message=AssistantMessage(content='Here is the extracted information in JSON array format for the entities \\'Test\\' and \\'Marks\\' from all pages:\\n\\n```json\\n[\\n    {\"Test\": \"MID\", \"Marks\": 80},\\n    {\"Test\": \"FINAL\", \"Marks\": 90},\\n    {\"Test\": \"HALFYEAR\", \"Marks\": 100},\\n    {\"Test\": \"FINAL\", \"Marks\": 90},\\n    {\"Test\": \"FINAL\", \"Marks\": 90}\\n]\\n```\\n\\nNote: Page 4 was skipped as it only contained a dot (.) and no relevant information.', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]}\n",
            "Here is the extracted information in JSON array format for the entities 'Test' and 'Marks' from all pages:\n",
            "\n",
            "```json\n",
            "[\n",
            "    {\"Test\": \"MID\", \"Marks\": 80},\n",
            "    {\"Test\": \"FINAL\", \"Marks\": 90},\n",
            "    {\"Test\": \"HALFYEAR\", \"Marks\": 100},\n",
            "    {\"Test\": \"FINAL\", \"Marks\": 90},\n",
            "    {\"Test\": \"FINAL\", \"Marks\": 90}\n",
            "]\n",
            "```\n",
            "\n",
            "Note: Page 4 was skipped as it only contained a dot (.) and no relevant information.\n",
            "chat response successfully saved to 'cresponse.json'\n",
            "cresponse.json\n",
            "{'id': 'b3fb04ca269c4bbfbcfab7323cdb841c', 'object': 'chat.completion', 'model': 'mistral-small-latest', 'usage': UsageInfo(prompt_tokens=370, completion_tokens=134, total_tokens=504, prompt_audio_seconds=Unset()), 'created': 1763605999, 'choices': [ChatCompletionChoice(index=0, message=AssistantMessage(content='Here is the extracted information in JSON array format for the entities \\'Test\\' and \\'Marks\\' from all pages:\\n\\n```json\\n[\\n    {\"Test\": \"MID\", \"Marks\": 80},\\n    {\"Test\": \"FINAL\", \"Marks\": 90},\\n    {\"Test\": \"HALFYEAR\", \"Marks\": 100},\\n    {\"Test\": \"FINAL\", \"Marks\": 90},\\n    {\"Test\": \"FINAL\", \"Marks\": 90}\\n]\\n```\\n\\nNote: Page 4 was skipped as it only contained a dot (.) and no relevant information.', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]}\n",
            " I am message2\n",
            "Error decoding JSON from raw_text: Expecting value: line 1 column 1 (char 0)\n",
            "{'success': False, 'error': 'Invalid JSON format in chat response', 'source_text': '{\"pages\":[{\"index\":0,\"markdown\":\"Page 1\\\\nTest : MID\\\\nMarks : 80\\\\nName : RAGHAV\\\\n\\\\nTest : FINAL\\\\nMarks: 90\\\\nName : Rita\",\"images\":[],\"dimensions\":{\"dpi\":200,\"height\":2339,\"width\":1654}},{\"index\":1,\"markdown\":\"Test: HALFYEAR\\\\nMarks: 100\\\\nName : Mina\",\"images\":[],\"dimensions\":{\"dpi\":200,\"height\":2339,\"width\":1654}},{\"index\":2,\"markdown\":\"Test : FINAL\\\\nMarks: 90\\\\nName : Rita\",\"images\":[],\"dimensions\":{\"dpi\":200,\"height\":2339,\"width\":1654}},{\"index\":3,\"markdown\":\"Test : FINAL\\\\nMarks: 90\\\\nName : Rita\",\"images\":[],\"dimensions\":{\"dpi\":200,\"height\":2339,\"width\":1654}},{\"index\":4,\"markdown\":\".\",\"images\":[],\"dimensions\":{\"dpi\":200,\"height\":2339,\"width\":1654}}],\"model\":\"mistral-ocr-2505-completion\",\"usage_info\":{\"pages_processed\":5,\"doc_size_bytes\":60816},\"document_annotation\":null}'}\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "##import mcp_util\n",
        "#import OS\n",
        "sys.path.append('../')\n",
        "#from mcp_util.config import FastMCP, Context\n",
        "#from mcp_util.logger import get_logger, current_tool_name\n",
        "#from mcp_util.constants import SERVER_NAME\n",
        "#import OS\n",
        "import base64\n",
        "import tempfile\n",
        "import time\n",
        "from typing import List, Dict,Any, Annotated\n",
        "from pydantic import BaseModel, Field, SecretStr\n",
        "from mistralai import Mistral\n",
        "import base64\n",
        "import json\n",
        "api_key1=\"g5eRGlSC6sETGwyzipp5qM1bBEthhO84\"\n",
        "client = Mistral(api_key=api_key1)\n",
        "class JSON_Label_List(BaseModel):\n",
        "  json_:List = Field(description=\"List of label and value pair extracted from the text\")\n",
        "def base64_to_temp_pdf(pdf_base64: str) -> str:\n",
        "    \"\"\"Convert base64 data to temporary PDF file.\"\"\"\n",
        "    base64_data = pdf_base64\n",
        "    try:\n",
        "      if base64_data.startswith('data:'):\n",
        "        base64_data = base64_data.split(',')[1]\n",
        "      #decode base 64 data\n",
        "      pdf_data = base64.b64decode(base64_data)\n",
        "      #create temporaty file\n",
        "      temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')\n",
        "      temp_file.write(pdf_data)\n",
        "      temp_file.close()\n",
        "      return temp_file.name\n",
        "    except Exception as e:\n",
        "      print(f\"Error decoding base64 data: {e}\")\n",
        "      return None\n",
        "\n",
        "\n",
        "\n",
        "def mistral_extract_document_entities(\n",
        "    pdf_base64: Annotated[str, \"Base64 encoded PDF file data to etract entities from\"],\n",
        "    entities: Annotated[List[str], \"List of entities to extract from the PDF\"] =[],\n",
        ") -> Dict[str,Any]:\n",
        "    \"\"\"\n",
        "    Extract entities from a PDF using MistralAI\n",
        "    Args:\n",
        "        base64_data: Base64 encoded PDF file data to etract entities from\n",
        "        entities: List of entities to extract, each with 'name' and 'description' keys\n",
        "    Returns:\n",
        "        Dictionary containing the extracted entities\n",
        "    \"\"\"\n",
        "    base64_data = pdf_base64\n",
        "    temp_pdf_file = None\n",
        "    try:\n",
        "        result1 = client.ocr.process(\n",
        "            model = \"mistral-ocr-latest\",\n",
        "            document = {\n",
        "                \"type\": \"document_url\",\n",
        "                \"data\": base64_data,\n",
        "                \"document_url\": f\"data:application/pdf;base64,{pdf_base64}\"\n",
        "            },\n",
        "            include_image_base64 = True\n",
        "        )\n",
        "        extracted_text = result1.model_dump_json()\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert in extracting information.\n",
        "        The information you need to extract is : {entities} for all pages\n",
        "        note - Output should be in json array format(entity as key and value as value).\n",
        "        Document Text : {extracted_text}\n",
        "        \"\"\"\n",
        "        messagesP = [\n",
        "\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error during OCR processing: {e}\")\n",
        "        return None # Return None if OCR fails\n",
        "    finally:\n",
        "          #if temp_pdf_path and os:\n",
        "           # os.remove(temp_pdf_file)\n",
        "            pass # Use pass here if you don't want to return\n",
        "\n",
        "    chat_response = client.chat.complete(\n",
        "        model = \"mistral-small-latest\",\n",
        "        messages = messagesP\n",
        "    )\n",
        "    print(\"DICTONARY\")\n",
        "    messages1 = dict(chat_response)\n",
        "    print(messages1)\n",
        "    raw_text = chat_response.choices[0].message.content\n",
        "    print(raw_text)\n",
        "    file1 = \"cresponse.json\"\n",
        "    try:\n",
        "      with open(file1, \"w\", encoding =\"utf-8\") as file:\n",
        "        file.write(raw_text)\n",
        "        print(f\"chat response successfully saved to '{file1}'\")\n",
        "    except IOError as e:\n",
        "          print(f\"Error writing to file '{file1}': {e}\")\n",
        "          return None\n",
        "    print(file1)\n",
        "    messages2 = {k: v.replace(\"\\n\",\"\") if isinstance(v, str) else v for k, v in messages1.items()}\n",
        "    print(messages2)\n",
        "    print(\" I am message2\")\n",
        "    extracted_entities =[]\n",
        "    # The raw_text is a string, not a list, so iterating over it character by character is incorrect.\n",
        "    # Assuming raw_text contains a JSON string representing a list of dictionaries:\n",
        "    try:\n",
        "        raw_text_list = json.loads(raw_text)\n",
        "        for row in raw_text_list:\n",
        "            new_row = {key: row[key] for key in entities if key in row}\n",
        "            extracted_entities.append(new_row)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON from raw_text: {e}\")\n",
        "        # Handle the case where raw_text is not a valid JSON list\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"error\": \"Invalid JSON format in chat response\",\n",
        "            \"source_text\": extracted_text\n",
        "        }\n",
        "\n",
        "    return{\n",
        "        \"success\": True,\n",
        "        \"extracted_entities\" : extracted_entities, # Return the processed list\n",
        "        \"source_text\": extracted_text,\n",
        "       # \"source_file\": temp_pdf_file\n",
        "\n",
        "    }\n",
        "    # The finally block below is misplaced and will execute before the return above.\n",
        "    # It also has an unnecessary return None which would prevent the function from returning the actual results.\n",
        "    # I will remove this misplaced finally block.\n",
        "#finally:\n",
        "      #if temp_pdf_path and os:\n",
        "       # os.remove(temp_pdf_file)\n",
        "        #return None\n",
        "\n",
        "\n",
        "\n",
        "pdf_path = \"/content/OCR_DOC3.pdf\"\n",
        "encoded = \"\"\n",
        "with open(pdf_path, \"rb\") as f:\n",
        "    encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "#return encoded # This return is outside the function and will cause an error. Commenting it out.\n",
        "results  = mistral_extract_document_entities(encoded, [\"Test\",\"Marks\"])\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mistral_extract_document_entities(\n",
        "    pdf_base64: Annotated[str, \"Base64 encoded PDF file data to etract entities from\"],\n",
        "    entities: Annotated[List[str], \"List of entities to extract from the PDF\"] =[],\n",
        ") -> Dict[str,Any]:\n",
        "    \"\"\"\n",
        "    Extract entities from a PDF using MistralAI\n",
        "    Args:\n",
        "        base64_data: Base64 encoded PDF file data to etract entities from\n",
        "        entities: List of entities to extract, each with 'name' and 'description' keys\n",
        "    Returns:\n",
        "        Dictionary containing the extracted entities\n",
        "    \"\"\"\n",
        "    base64_data = pdf_base64\n",
        "    temp_pdf_file = None\n",
        "    try:\n",
        "        new_var = client.ocr.process(\n",
        "            model = \"mistral-ocr-latest\",\n",
        "            document = {\n",
        "                \"type\": \"document_url\",\n",
        "                \"data\": base64_data,\n",
        "                \"document_url\": f\"data:application/pdf;base64,{pdf_base64}\"\n",
        "            },\n",
        "            include_image_base64 = True\n",
        "        )\n",
        "        result1 = new_var\n",
        "        extracted_text = result1.model_dump_json()\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert in extracting information.\n",
        "        The information you need to extract is : {entities} for all pages\n",
        "        note - Output should be in json array format(entity as key and value as value).\n",
        "        Document Text : {extracted_text}\n",
        "        \"\"\"\n",
        "        messagesP = [\n",
        "\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error during OCR processing: {e}\")\n",
        "        return None # Return None if OCR fails\n",
        "    finally:\n",
        "          #if temp_pdf_path and os:\n",
        "           # os.remove(temp_pdf_file)\n",
        "            pass # Use pass here if you don't want to return\n",
        "\n",
        "    chat_response = client.chat.complete(\n",
        "        model = \"mistral-small-latest\",\n",
        "        messages = messagesP\n",
        "    )\n",
        "    print(\"DICTONARY\")\n",
        "    messages1 = dict(chat_response)\n",
        "    print(messages1)\n",
        "    raw_text = chat_response.choices[0].message.content\n",
        "    print(raw_text)\n",
        "    file1 = \"cresponse.json\"\n",
        "    try:\n",
        "      with open(file1, \"w\", encoding =\"utf-8\") as file:\n",
        "        file.write(raw_text)\n",
        "        print(f\"chat response successfully saved to '{file1}'\")\n",
        "    except IOError as e:\n",
        "          print(f\"Error writing to file '{file1}': {e}\")\n",
        "          return None\n",
        "    print(file1)\n",
        "    messages2 = {k: v.replace(\"\\n\",\"\") if isinstance(v, str) else v for k, v in messages1.items()}\n",
        "    print(messages2)\n",
        "    print(\" I am message2\")\n",
        "    extracted_entities =[]\n",
        "    # The raw_text is a string, not a list, so iterating over it character by character is incorrect.\n",
        "    # Assuming raw_text contains a JSON string representing a list of dictionaries:\n",
        "    try:\n",
        "        raw_text_list = json.loads(raw_text)\n",
        "        for row in raw_text_list:\n",
        "            new_row = {key: row[key] for key in entities if key in row}\n",
        "            extracted_entities.append(new_row)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON from raw_text: {e}\")\n",
        "        # Handle the case where raw_text is not a valid JSON list\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"error\": \"Invalid JSON format in chat response\",\n",
        "            \"source_text\": extracted_text\n",
        "        }\n",
        "\n",
        "    return{\n",
        "        \"success\": True,\n",
        "        \"extracted_entities\" : extracted_entities, # Return the processed list\n",
        "        \"source_text\": extracted_text,\n",
        "       # \"source_file\": temp_pdf_file\n",
        "\n",
        "    }\n",
        "    # The finally block below is misplaced and will execute before the return above.\n",
        "    # It also has an unnecessary return None which would prevent the function from returning the actual results.\n",
        "    # I will remove this misplaced finally block.\n",
        "#finally:\n",
        "      #if temp_pdf_path and os:\n",
        "       # os.remove(temp_pdf_file)\n",
        "        #return None\n",
        "\n",
        "\n",
        "\n",
        "pdf_path = \"/content/OCR_DOC3.pdf\"\n",
        "encoded = \"\"\n",
        "with open(pdf_path, \"rb\") as f:\n",
        "    encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "#return encoded # This return is outside the function and will cause an error. Commenting it out.\n",
        "results  = mistral_extract_document_entities(encoded, [\"name\", \"value\"])\n",
        "print(results)"
      ],
      "metadata": {
        "id": "QJm5pltkTgXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "e48ede11-c141-473f-cb2e-ced4581d8794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SDKError",
          "evalue": "API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"service_tier_capacity_exceeded\",\"param\":null,\"code\":\"3505\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSDKError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-708477008.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m#return encoded # This return is outside the function and will cause an error. Commenting it out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mresults\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmistral_extract_document_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-708477008.py\u001b[0m in \u001b[0;36mmistral_extract_document_entities\u001b[0;34m(pdf_base64, entities)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mpass\u001b[0m \u001b[0;31m# Use pass here if you don't want to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     chat_response = client.chat.complete(\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mistral-small-latest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessagesP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mistralai/chat.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, prediction, parallel_tool_calls, prompt_mode, safe_prompt, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4XX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mhttp_res_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDKError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"API error occurred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_res_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"5XX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mhttp_res_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSDKError\u001b[0m: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"service_tier_capacity_exceeded\",\"param\":null,\"code\":\"3505\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3veIepgTgT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}